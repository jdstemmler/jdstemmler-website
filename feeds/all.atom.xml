<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jayson Stemmler</title><link href="http://jdstemmler.com/" rel="alternate"></link><link href="http://jdstemmler.com/feeds/all.atom.xml" rel="self"></link><id>http://jdstemmler.com/</id><updated>2016-02-05T00:00:00-08:00</updated><entry><title>MLS Standings</title><link href="http://jdstemmler.com/posts/2016/Feb/mls-standings" rel="alternate"></link><published>2016-02-05T00:00:00-08:00</published><updated>2016-02-05T00:00:00-08:00</updated><author><name>Jayson Stemmler</name></author><id>tag:jdstemmler.com,2016-02-05:/posts/2016/Feb/mls-standings</id><summary type="html">&lt;p&gt;In June of 2015 I attended Seattle Data Day in downtown Seattle and learned a number of interesting new things about python and data science. One of the sessions I attended was a workshop on &lt;a href="http://shop.oreilly.com/product/0636920034391.do" target="_blank"&gt;web scraping with python&lt;/a&gt; presented by &lt;a href="http://www.pythonscraping.com/node/5" target="_blank"&gt;Ryan Mitchell&lt;/a&gt;. At the end, we were encouraged to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In June of 2015 I attended Seattle Data Day in downtown Seattle and learned a number of interesting new things about python and data science. One of the sessions I attended was a workshop on &lt;a href="http://shop.oreilly.com/product/0636920034391.do" target="_blank"&gt;web scraping with python&lt;/a&gt; presented by &lt;a href="http://www.pythonscraping.com/node/5" target="_blank"&gt;Ryan Mitchell&lt;/a&gt;. At the end, we were encouraged to pick a site and play around with scraping and getting the data into python.&lt;/p&gt;
&lt;p&gt;My site of choice was the Major League Soccer &lt;a href="http://www.mlssoccer.com/results" target="_blank"&gt;results map&lt;/a&gt; for the current season. As a big fan of soccer (specifically, the Seattle Sounders) I thought it would be fun to play around with some of the league standings for the current season and make some plots of not only the most recent standings, but the standings throughout the season. With that, I'll show some plots and talk a little bit about how the W/L/D gets converted into points. Oh, and all the code for this can be found over on my personal GitHub page &lt;a href="https://github.com/jdstemmler/mls-standings" target="_blank"&gt;in this repository&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;The web scraper&lt;/h2&gt;
&lt;p&gt;The function of the web scraper is actually pretty simple. It goes out to the page and fetches the table. From there, the python code parses the table by going through each of the rows and collecting the win-loss-draw information for each game number. It then converts each win, loss, and draw into 3, 1, or zero points respectively. It then saves this information out to a .csv file.&lt;/p&gt;
&lt;h2&gt;Plots&lt;/h2&gt;
&lt;p&gt;Now the fun part. Here is a plot of the standings by team for each game in the season. It's a little bit messy, but rather informative. On the x-axis is the game number with the cumulative number of points each team has on the y-axis. Lines are colored by team in the legend on the right side of the plot.
&lt;a href="https://storage.googleapis.com/jdstemmler-blog-images/2016/02/mls-standings/standings_by_game.png" title="MLS Point Standings"&gt;&lt;img alt="MLS Point Standings" src="https://storage.googleapis.com/jdstemmler-blog-images/2016/02/mls-standings/standings_by_game.png" title="MLS Point Standings"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I have a lot of fun looking at this plot. You can clearly see in some teams when they went on winning or losing streaks, how many games each team has played, and generally get a sense of the performance throughout the season. However, the plot is quite cluttered. I chose the colors for each team based off of a best-guess of the representative color for the team, but there are obviously some similarities in the colors which makes it difficult to differentiate between some teams.&lt;/p&gt;
&lt;p&gt;If we don't really care about how a team has performed throughout the season, we can take a look at only the most recent reporting of the number of points for each team. Additionally, it is of interest to know which teams will make the playoffs at the end of the season (top 6 from both the Western and Eastern conferences) and how well the conferences are doing compared to one another.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://storage.googleapis.com/jdstemmler-blog-images/2016/02/mls-standings/current_points_standings.png" title="Current Point Standings"&gt;&lt;img alt="Current Point Standings" src="https://storage.googleapis.com/jdstemmler-blog-images/2016/02/mls-standings/current_points_standings.png" title="Current Point Standings"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This plot clearly shows all those metrics. Western conference in red on the left, Eastern in blue on the right, sorted by total number of points with dotted black lines on each of the conferences to show the cutoff point of the playoffs. What this figure doesn't really convey as well as the first plot is the disparity between the teams with respect to the number of games played. D.C. United, for example, has played 7 more games (at the time of this writing) than the Montreal Impact and thus has the potential to have 21 additional points simply because they've played more games.&lt;/p&gt;
&lt;p&gt;This next figure shows similar information as above, but with a few small tweaks. To help address the issue of the games-played difference, these standings show the number of points each team had at the most recent game that all teams have played. The lighter colors, then, show how many points each team has earned since that game, if they've played additional games.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://storage.googleapis.com/jdstemmler-blog-images/2016/02/mls-standings/level_game_points_standings.png" title="Level Games"&gt;&lt;img alt="Level Game Points Standings" src="https://storage.googleapis.com/jdstemmler-blog-images/2016/02/mls-standings/level_game_points_standings.png" title="Level Games"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This plot could really use some additional information, such as just exactly how many additional games each team has played and not just points. But it does give you a better sense of the standings at the most recent point in time when all teams had played the same number of games.&lt;/p&gt;
&lt;p&gt;One way to get around this issue entirely is to look at average points per game (PPG). This is exactly what it sounds like - total number of points divided by the total number of games played. This essentially ranks teams by the mean &lt;em&gt;slope&lt;/em&gt; of the line shown all the way back in the first plot. Doing this gives you yet another way to look at the standings:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://storage.googleapis.com/jdstemmler-blog-images/2016/02/mls-standings/ppg_standings.png" title="Points per Game"&gt;&lt;img alt="Points per Game Standings" src="https://storage.googleapis.com/jdstemmler-blog-images/2016/02/mls-standings/ppg_standings.png" title="Points per Game"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;These plots are obviously a little bit out of date by this point, but they get the points across. However, if you click-through to the linked images those should be updated within the last 6 hours. I have this script running on a server that pulls down the standings and makes the plots at that frequency, so you can never be without the most recent standings!&lt;/p&gt;
&lt;p&gt;I hope you enjoyed looking through this. It was a really great learning experience to combine the web scraping component with some sports. There is so much more you could do with this data, such as looking at the performance of Western conference teams vs Eastern when they play in-conference or out, longest winning or losing (or tying) streaks, or even looking at data from previous seasons.&lt;/p&gt;
&lt;p&gt;Feel free to comment with any suggestions for things to look at or improvements to any of my methods. I welcome your feedback!&lt;/p&gt;</content><category term="soccer"></category><category term="python"></category><category term="web scraping"></category></entry><entry><title>Stone Soup</title><link href="http://jdstemmler.com/posts/2016/Jan/stone-soup" rel="alternate"></link><published>2016-01-11T00:00:00-08:00</published><updated>2016-01-11T00:00:00-08:00</updated><author><name>Jayson Stemmler</name></author><id>tag:jdstemmler.com,2016-01-11:/posts/2016/Jan/stone-soup</id><summary type="html">&lt;p&gt;When I'm not doing data science, one of the things I like to do is cook.
Often times when I finish a recipe I'm left with a handful of leftover
ingredients that I don't quite know how to use up. Because of this, I
decided to make an ingredient-based recipe …&lt;/p&gt;</summary><content type="html">&lt;p&gt;When I'm not doing data science, one of the things I like to do is cook.
Often times when I finish a recipe I'm left with a handful of leftover
ingredients that I don't quite know how to use up. Because of this, I
decided to make an ingredient-based recipe search tool to help me find
recipes so that my spare ingredients don't go to waste.&lt;/p&gt;
&lt;h2&gt;The Story of Stone Soup&lt;/h2&gt;
&lt;p&gt;Stone soup is an old folk tale where hungry travelers build a meal out of
individual donated ingredients from many of the townsfolk.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Some travelers come to a village, carrying nothing more than an empty cooking pot. Upon their arrival, the villagers are unwilling to share any of their food stores with the hungry travelers.&lt;/p&gt;
&lt;p&gt;Then the travelers go to a stream and fill the pot with water, drop a large stone in it, and place it over a fire. One of the villagers becomes curious and asks what they are doing. The travelers answer that they are making "stone soup", which tastes wonderful, although it still needs a little bit of garnish to improve the flavor, which they are missing.&lt;/p&gt;
&lt;p&gt;The villager does not mind parting with a few carrots to help them out, so that gets added to the soup. Another villager walks by, inquiring about the pot, and the travelers again mention their stone soup which has not reached its full potential yet. The villager hands them a little bit of seasoning to help them out.&lt;/p&gt;
&lt;p&gt;More and more villagers walk by, each adding another ingredient. Finally, a delicious and nourishing pot of soup is enjoyed by all.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Stone Stoup in Action&lt;/h2&gt;
&lt;p&gt;Let's see this in action. There's a simple web interface:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Stone Soup homepage" src="https://storage.googleapis.com/jdstemmler-blog-images/2016/01/stone-soup/homepage.jpg"&gt;&lt;/p&gt;
&lt;p&gt;The search box takes in a comma separated list of ingredients that you'd like
to search for. Recipe categories can be selected via the check-boxes below the
search box.&lt;/p&gt;
&lt;p&gt;The results page presents up to 12 recipes that match the search:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Stone Soup results" src="https://storage.googleapis.com/jdstemmler-blog-images/2016/01/stone-soup/results.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Clicking on a recipe takes the user to the webpage for that recipe in a new tab
where they can do with it what they want.&lt;/p&gt;
&lt;h2&gt;Behind the Scenes&lt;/h2&gt;
&lt;p&gt;There are two main parts to the search and analysis behind Stone Soup:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Recipe aggregation and topic analysis&lt;/li&gt;
&lt;li&gt;Matching search terms to recipes&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Recipe Aggregation and Topic analysis&lt;/h3&gt;
&lt;p&gt;Before a user even visits the site the recipes must be collected, parsed, and
analyzed. For this project I used the entire &lt;a href="http://cooking.nytimes.com"&gt;New York Times recipe corpus&lt;/a&gt; (The code is written in such a way that it would be relatively trivial to either substitute for a different recipe site, or add more sources of recipes to provide deeper results). This was accomplished by using the NYTimes article search API to get a list of articles tagged as "recipes," and then downloading the raw HTML content of each recipe into a MongoDB collection.&lt;/p&gt;
&lt;p&gt;Each recipe in the corpus was then passed through a &lt;a href="https://github.com/jdstemmler/stone-soup/blob/master/tools/recipetools/parsers/recipe_parsers.py"&gt;recipe parser&lt;/a&gt; to extract the relevant details such as name, author, ingredients, directions, nutrition information, notes, and tags. Those that didn't fail (~17,000 out of ~20,000) became the source for my recipe search.&lt;/p&gt;
&lt;p&gt;To search for ingredients in the recipes, I created a "bag of ingredients" from the corpus of recipes. This included a column for each ingredient present in the corpus and a row for each recipe. This allows the search tool to look for any ingredient in the corpus and return only those recipes with the requested ingredient in them. More details about the implementation of "search" is described below in the next section.&lt;/p&gt;
&lt;p&gt;In addition to creating a "bag of ingredients," I created a "bag of directions" by splitting up the text in the directions into bi- and tri-grams (sequences of two and three words). I then computed the TF-IDF (term frequency - inverse document frequency) matrix for the entire corpus. Finally, I used NMF (non-negative matrix factorization) to decompose the large TF-IDF matrix into eight topics. The end result of this is a matrix that has a row for each recipe and a "strength" value for each of the eight topics. This matrix will be utilized during the search procedure.&lt;/p&gt;</content><category term="cooking"></category><category term="web scraping"></category><category term="python"></category></entry></feed>